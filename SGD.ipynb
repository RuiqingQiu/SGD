{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test result function\n",
    "def frobenius_norm(M1, M2):\n",
    "    #print M1\n",
    "    #print M2\n",
    "    total = 0.0\n",
    "    for a,b in zip(M1, M2):\n",
    "        for c, d in zip(a, b):\n",
    "            total += (c - d)*(c - d)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dimension of each example in the dataset\n",
    "d = 15\n",
    "# k is the top pricipal calculated by the eigenvectors, right now just fix it\n",
    "k = 5\n",
    "# fix the learning rate\n",
    "learning_rate = 0.00001\n",
    "# preprocess the data\n",
    "data_set = []\n",
    "data_set_done = []\n",
    "if os.path.exists('new_data'):\n",
    "    with open('new_data') as data:\n",
    "        for line in data:\n",
    "            data_set_done.append(map(float, line.split()))\n",
    "\n",
    "else:\n",
    "    with open('adult.data.txt') as data:\n",
    "        for line in data:\n",
    "            # '\\s' matches whitespace\n",
    "            tmp = re.sub(r'\\s', '', line).split(',')\n",
    "            data_set.append(tmp)\n",
    "    print data_set\n",
    "\n",
    "    feature_vector_size = len(data_set[0])\n",
    "    print \"feature vector is  \" ,feature_vector_size\n",
    "    print \"data set size is \", len(data_set)\n",
    "    tmp = data_set[0]\n",
    "\n",
    "    # find out which feature is not a digit\n",
    "    non_digit_index = []\n",
    "    for i in range (0,feature_vector_size):\n",
    "        if tmp[i].isdigit():\n",
    "            continue\n",
    "        else:\n",
    "            non_digit_index.append(i)\n",
    "    print non_digit_index\n",
    "\n",
    "    # make each string feature to become a number\n",
    "\n",
    "    # Copy\n",
    "    modified_data_set= []\n",
    "    for item in data_set:\n",
    "        modified_data_set.append(item)\n",
    "\n",
    "\n",
    "    print \"data before processed dimension is \", len(modified_data_set[0])\n",
    "    #print modified_data_set\n",
    "    item_list = []\n",
    "    count = 0\n",
    "    dimension_to_increase = 0\n",
    "    # for all the non_digit index, count how many differnt items\n",
    "    for i in non_digit_index:\n",
    "        # clear the item list to find different string for same feature\n",
    "        items = []\n",
    "        # loop through the whole data set\n",
    "        for vector in data_set:\n",
    "            # get the corresponsding item\n",
    "            tmp = vector[i]\n",
    "            # it already in the list\n",
    "            if tmp in items:\n",
    "                continue\n",
    "            else:\n",
    "                # otherwise append to the list\n",
    "                items.append(tmp)\n",
    "        dimension_to_increase = dimension_to_increase + len(items)-1\n",
    "        #print \"item is \"\n",
    "        #print items\n",
    "        #print \"\\n\\n\"\n",
    "        # loop through the whole data set to replace the feature\n",
    "        for j in range(len(modified_data_set)):\n",
    "            v = modified_data_set[j]\n",
    "            #print v\n",
    "            # get the item in the vector\n",
    "            #print \"accessing \", i+count\n",
    "            tmp = v[i+count]\n",
    "            index  = items.index(tmp)\n",
    "            front = v[0:i+count]\n",
    "            end = v[i+1+count:len(v)]\n",
    "            zeros = [0]*len(items)\n",
    "            zeros[index] = 1\n",
    "            front.extend(zeros)\n",
    "            front.extend(end)\n",
    "            modified_data_set[j] = front\n",
    "            #print \"result is \", modified_data_set[j]\n",
    "            #v[i] = float(index)\n",
    "        count = count + len(items)-1\n",
    "    for v in modified_data_set:\n",
    "        v = map(float, v)\n",
    "        data_set_done.append(v)\n",
    "    print \"dimension to increase \", dimension_to_increase\n",
    "    print \"data processed dimension is \", len(data_set_done[0])\n",
    "    #print data_set_done\n",
    "    print \"size of data set done is \", len(data_set_done)\n",
    "\n",
    "f = open('new_data', 'w')\n",
    "for vector in data_set_done:\n",
    "    for num in vector:\n",
    "        f.write(str(num)+\" \")\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M is \n",
      "[[  1.67459915e+03   1.57089770e+00   3.50935168e+00   2.56490280e+01]\n",
      " [  1.61757931e+00   3.98636406e-02   0.00000000e+00   0.00000000e+00]\n",
      " [  3.55606400e+00   3.07115875e-05   7.80381438e-02   0.00000000e+00]\n",
      " [  2.56957403e+01   3.07115875e-05   0.00000000e+00   6.97030189e-01]]\n",
      "U is [[ -9.99879535e-01  -1.44026855e-02   4.37200764e-03  -3.79000455e-03]\n",
      " [ -9.65624455e-04  -8.36676973e-02   3.21253651e-01   9.43289391e-01]\n",
      " [ -2.12286401e-03  -2.13455456e-01  -9.30412873e-01   2.97933125e-01]\n",
      " [ -1.53452583e-02   9.73256928e-01  -1.76377046e-01   1.46378322e-01]]\n",
      "V is [[ -9.99880048e-01  -9.37758710e-04  -2.09497964e-03  -1.53173775e-02]\n",
      " [ -1.43971548e-02  -8.17449317e-02  -2.11797035e-01   9.73782575e-01]\n",
      " [  4.34250593e-03   3.19375564e-01  -9.31194941e-01  -1.75659822e-01]\n",
      " [ -3.70876811e-03   9.44095406e-01   2.96670875e-01   1.43723696e-01]]\n",
      "[2802284.9025905216]\n",
      "2708903.32026\n",
      "1439539.84124\n",
      "11781.8800014\n",
      "479.606277653\n",
      "449.758410049\n",
      "454.508644565\n",
      "455.729363606\n",
      "455.933832516\n",
      "455.923612461\n",
      "455.869883746\n",
      "455.807133848\n",
      "455.742232279\n",
      "455.676543377\n",
      "455.610337358\n",
      "455.54366719\n",
      "455.476542731\n",
      "455.408965293\n",
      "455.340934509\n",
      "455.272449683\n",
      "455.203510066\n",
      "[2802284.9025905216, 2708903.3202586789, 1439539.8412366041, 11781.880001385745, 479.60627765297284, 449.75841004901702, 454.50864456467667, 455.7293636059328, 455.93383251574704, 455.92361246113177, 455.86988374588628, 455.80713384823719, 455.74223227917525, 455.67654337697286, 455.61033735849503, 455.54366719047692, 455.47654273055315, 455.40896529333992, 455.34093450884268, 455.27244968271214, 455.20351006590749]\n"
     ]
    }
   ],
   "source": [
    "# U and V are d x k dimension matrix\n",
    "v = np.random.rand(len(data_set_done[0]),k)\n",
    "#print \"V start with, \", v\n",
    "u = np.random.rand(len(data_set_done[0]),k)\n",
    "#print \"U start with, \", u\n",
    "\n",
    "#print \"result of the caulcation is \", np.transpose(data_set_done[0])\n",
    "\n",
    "# data set size covariance matrix M\n",
    "N = len(data_set_done)\n",
    "M = np.array(data_set_done[0]) * np.transpose(np.array(data_set_done[0])) / N\n",
    "for i in range(1, len(data_set_done)):\n",
    "    M = M + (np.array([data_set_done[i]]) * np.transpose(np.array([data_set_done[i]]))) / N\n",
    "print \"M is \"\n",
    "print M\n",
    "\n",
    "U, s, V = np.linalg.svd(M, full_matrices=True)\n",
    "\n",
    "print \"U is\", U\n",
    "\n",
    "print \"V is\", V\n",
    "distance = []\n",
    "distance.append(frobenius_norm(M, np.dot(U,np.transpose(V))))\n",
    "print distance\n",
    "\n",
    "# SGD function\n",
    "# run the whole optimization process 10 times\n",
    "for j in range(0, 20):\n",
    "    # do u 100 rounds\n",
    "    #for counter in range (0,10):\n",
    "        #print counter\n",
    "        # update u len(data_set) iterations\n",
    "    for t in range(0, 100):\n",
    "            #print (data_set[t] * np.transpose(data_set[t]) - np.dot(u,np.transpose(v)))\n",
    "            # need to do np.dot() for matrix multiplication\n",
    "        u = u + learning_rate * np.dot(M - np.dot(u,np.transpose(v)), v)\n",
    "        #u = u - learning_rate * np.dot((data_set_done[t] * np.transpose(data_set_done[t]) - np.dot(u,np.transpose(v))), v)\n",
    "            #print \"u is\"\n",
    "            #print u\n",
    "    # do v 100 rounds\n",
    "    #for counter in range (0,10):\n",
    "        #print counter\n",
    "        # update v len(data_set) iterations\n",
    "    for t in range(0, 100):\n",
    "        v = v + learning_rate * np.dot(M - np.dot(u, np.transpose(v)), u)\n",
    "        #v = v - learning_rate * np.dot((data_set_done[t] * np.transpose(data_set_done[t]) - np.dot(u, np.transpose(v))), u)\n",
    "            #print \"v is \"\n",
    "            #print v\n",
    "#     print \"u is\"\n",
    "#     print u\n",
    "#     print \"v is\"\n",
    "#     print v\n",
    "    # print \"result is\"\n",
    "\n",
    "    # print np.dot(u, np.transpose(v))\n",
    "    result = frobenius_norm(M, np.dot(u,np.transpose(v)))\n",
    "    print result\n",
    "    distance.append(result)\n",
    "print distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
